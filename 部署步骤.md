#前置条件#
	* 系统为类linux系统
	* 已部署1.8或以上版本的java环境（jdk）
	* 已安装maven
#安装步骤#
	* 首先下载elasticsearch logstash kafka程序包
	* Elastic Search 安装
		1. 增加系统最大文件打开数量
			将以下内容追加至 /etc/sysctl.conf 
				vm.max_map_count=262144
			然后执行 sudo sysctl -p
			将以下内容追加至 /etc/security/limits.conf
				*    soft nofile 65536
				*    hard nofile 65536
				root soft nofile 65536
				root hard nofile 65536
			将以下内容追加至 /etc/pam.d/common-session
				session required pam_limits.so
			将以下内容追加至 /etc/pam.d/common-session-noninteractive
				session required pam_limits.so
			配置完毕后重启计算机
		2. 把configs/elasticsearch下的配置文件放至config下
		3. nohup bin/elasticsearch > my_esearch.log &
		4. 用 tail -f ./myesearch.log 查看log是否启动正常
		5. 通过RESTFUL方式增加esearch模版，依此执行以下命令
			curl -XGET 'localhost:9200/_template/logstash_1?pretty'
			
			curl -XDELETE 'localhost:9200/_template/logstash_1?pretty'
			
			
			curl -XPUT 'localhost:9200/_template/logstash_1?pretty' -H 'Content-Type: application/json' -d'
			{
			    "template": "logstash-*",
			    "order": 1,
			    "mappings": {
			        "_default_": {
			            "_all": {
			                "enabled": true,
			                "omit_norms": true
			            },
			            "dynamic_templates": [
			                {
			                    "message_field": {
			                        "path_match": "message",
			                        "mapping": {
			                            "norms": false,
			                            "type": "text"
			                        },
			                        "match_mapping_type": "string"
			                    }
			                },
			                {
			                    "string_fields": {
			                        "mapping": {
			                            "type": "string",
			                            "index": "not_analyzed",
			                            "doc_values": true
			                        },
			                        "match_mapping_type": "string",
			                        "match": "*"
			                    }
			                }
			            ]
			        }
			    }
			}
			'
		
		
	* Kafka 安装
		1. 把configs/kafka/下的配置文件放至config下
		2. 执行命令启动 zookeeper，nohup bin/zookeeper-server-start.sh config/zookeeper.properties > my_zookeepper.log & 
		3. 执行命令启动 kafkaserver，
			nohup bin/kafka-server-start.sh config/server.properties > my_kafkaserver.log &
			nohup bin/kafka-server-start.sh config/server-1.properties > my_kafkaserver1.log & 
		4. 执行命令创建 topic，bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 1 --topic my-replicated-topic
		5.	执行testIn.sh然后随便输入一些测试信息回车，执行testOut.sh看是否能正常读取到消息
		
	* Logtsash 安装
		1. 把 configs/logstash/logstash-simple.conf文件放至logstash目录下
		2. 执行命令启动 logstash， nohup bin/logstash -f logstash-simple.conf > my_logstash.log &
		3. 用 tail -f ./my_logstash.log 查看log是否启动正常
	* 代码部署
		1. 执行脚本打jar包，./startup.sh -p
		2. 运行jar包，nohup java -jar log-filter-1.0.0.jar &
		3. 在/logs/下查看log是否启动正常，job-log.log 为定时任务日志，message-log.log为实时日志
	 
		
	